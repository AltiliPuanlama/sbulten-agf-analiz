import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

st.set_page_config(page_title="Trakus YarÄ±ÅŸ Analiz", layout="wide")
st.title("ğŸ Trakus YarÄ±ÅŸ Analiz Paneli")

# KullanÄ±cÄ±dan tarih al
tarih_input = st.date_input("Tarih SeÃ§iniz")
tarih = tarih_input.strftime("%Y%m%d")

# Åehir listesini Ã§ek
@st.cache_data(show_spinner=False)
def get_sehirler(tarih):
    url = f"http://91.151.93.198:5001/{tarih}"
    r = requests.get(url)
    soup = BeautifulSoup(r.text, "html.parser")
    linkler = soup.select("div.navigator a")
    return [{"isim": a.text.strip(), "sehir": a['href'].split("/")[-1]} for a in linkler]

# SeÃ§ilen ÅŸehrin koÅŸularÄ±nÄ± analiz et
def analyze_sehir(tarih, sehir):
    url = f"http://91.151.93.198:5001/{tarih}/{sehir}"
    r = requests.get(url)
    soup = BeautifulSoup(r.text, "html.parser")
    tablolar = soup.find_all("table")
    basliklar = soup.find_all(string=re.compile(r"KoÅŸu "))
    analizler = []

    for i, tablo in enumerate(tablolar):
        try:
            df = pd.read_html(str(tablo))[0]
            df.columns = [str(c) for c in df.columns]  # ğŸ‘ˆ TypeError Ã§Ã¶zÃ¼mÃ¼
            if df.empty or df.shape[1] < 5:
                continue
            baslik = basliklar[i].strip() if i < len(basliklar) else f"KoÅŸu {i+1}"
            analizler.append((baslik, df))
        except Exception:
            continue

    return analizler

# Åehirleri getir ve seÃ§tirme
sehirler = get_sehirler(tarih)
sehir_adi = st.selectbox("Åehir SeÃ§iniz", [s['isim'] for s in sehirler])

if st.button("Analizi BaÅŸlat"):
    with st.spinner("Veriler getiriliyor..."):
        analizler = analyze_sehir(tarih, sehir_adi)
    
    if not analizler:
        st.warning("Bu ÅŸehir iÃ§in analiz bulunamadÄ±.")
    else:
        for baslik, df in analizler:
            st.subheader(baslik)
            st.dataframe(df, use_container_width=True)
